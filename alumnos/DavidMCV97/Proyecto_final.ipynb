{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optimizacion:\n",
    "    def __init__(self,function):\n",
    "        self.f = function\n",
    "\n",
    "    def gradiente(self,x):\n",
    "        x = x.astype(np.float64)\n",
    "        h = np.float64(1e-4)\n",
    "        k = 1/(2*h)\n",
    "        n = x.shape[0]\n",
    "        grad = np.zeros(n).astype(np.float64)\n",
    "        for i in range(n):\n",
    "            aux1 = np.copy(x)\n",
    "            aux2 = np.copy(x)\n",
    "            aux1[i] = aux1[i]+h\n",
    "            aux2[i] = aux2[i]-h\n",
    "            grad[i] = self.f(aux1) - self.f(aux2)\n",
    "            grad[i] = grad[i]*k\n",
    "        return grad\n",
    "    \n",
    "    def hessiana(self,x):\n",
    "        x = x.astype(np.float64)\n",
    "        h = np.float64(1e-2)\n",
    "        k = 1/(h**2)\n",
    "        n = x.shape[0]\n",
    "        hess = np.zeros((n,n)).astype(np.float64)\n",
    "        for i in range(n):\n",
    "            for j in range(i+1):\n",
    "                if i == j:\n",
    "                    aux1 = np.copy(x)\n",
    "                    aux2 = np.copy(x)\n",
    "                    aux1[i] = aux1[i]+h\n",
    "                    aux2[i] = aux2[i]-h\n",
    "                    hess[i,j] = self.f(aux1) + self.f(aux2) - 2*self.f(x)\n",
    "                    hess[i,j] = hess[i,j]*k\n",
    "                else:\n",
    "                    aux1 = np.copy(x)\n",
    "                    aux2 = np.copy(x)\n",
    "                    aux3 = np.copy(x)\n",
    "                    aux1[i] = aux1[i]+h\n",
    "                    aux1[j] = aux1[j]+h\n",
    "                    aux2[i] = aux2[i]+h\n",
    "                    aux3[j] = aux3[j]+h\n",
    "                    hess[i,j] = self.f(aux1) - self.f(aux2) - self.f(aux3) + self.f(x)\n",
    "                    hess[i,j] = hess[i,j]*k\n",
    "                    hess[j,i] = hess[i,j]\n",
    "        return hess\n",
    "    \n",
    "    def es_optimo(self,x):\n",
    "        n = x.shape[0] \n",
    "        grad = abs(self.gradiente(x))\n",
    "        eps = np.float64(1e-10) * np.ones(n)\n",
    "        if all(grad < eps):\n",
    "            hess = self.hessiana(x)\n",
    "            if all (np.linalg.eigh(hess)[0] >= 0):\n",
    "                optimo = True\n",
    "            else:\n",
    "                optimo = False\n",
    "        else:\n",
    "            optimo = False\n",
    "        return optimo\n",
    "    \n",
    "    def wolfe(self,x,p,alpha,c1,c2):\n",
    "        aux = x + alpha*p\n",
    "        producto = self.gradiente(x).dot(p)\n",
    "        bueno = False\n",
    "        if self.f(aux) <= self.f(x) + c1*alpha*producto:\n",
    "            if self.gradiente(aux).dot(p) >= c2*producto:\n",
    "                bueno = True\n",
    "        return bueno\n",
    "    \n",
    "    def alpha(self,x,p,c1,c2,rho):\n",
    "        a = 1\n",
    "        i = 1\n",
    "        M = 5000\n",
    "        while i<M and self.wolfe(x,p,a,c1,c2)==False:\n",
    "            a = rho*a\n",
    "            i = i+1\n",
    "        if i==M:\n",
    "            print(\"iteraciones maximas alcanzadas en Wolfe\")\n",
    "        return a\n",
    "    \n",
    "    def volver_pd(self,x):\n",
    "        if np.all(np.linalg.eigvals(x) > 0) == True:\n",
    "            return x\n",
    "        else:\n",
    "            e = abs(np.linalg.eigvals(x))\n",
    "            l = min(e) + 3*np.finfo(float).eps\n",
    "            E = np.identity(len(x))\n",
    "            x = x+(l*E)\n",
    "        return x\n",
    "    \n",
    "    def busqueda_lineal_newton(self,x,modificada = False):\n",
    "        k=0\n",
    "        c1 = 0.1\n",
    "        c2 = 0.8\n",
    "        rho = 0.9\n",
    "        a = 1\n",
    "        while k<300 and self.es_optimo(x)==False:\n",
    "            B = self.hessiana(x)\n",
    "            g = -self.gradiente(x)\n",
    "            p = np.linalg.solve(B,g)\n",
    "            if modificada == True:\n",
    "                B = self.volver_pd(B)\n",
    "                a = self.alpha(x,p,c1,c2,rho)\n",
    "            x = x+a*p\n",
    "            k=k+1\n",
    "        if k==300:\n",
    "            print (\"iteraciones maximas alcanzadas en busqueda lineal\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: (2-x[0])**2 + (3-x[1])**2\n",
    "opt = optimizacion(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([0,0])\n",
    "opt.busqueda_lineal_newton(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
