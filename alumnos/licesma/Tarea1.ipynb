{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pos nos dice cuál derivada parcial queremos calcular, 0 <=pos <= xk.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivada_parcial(f, xk, pos):\n",
    "    eps= 0.0001\n",
    "    n = xk.size\n",
    "    h = np.zeros(n)\n",
    "    h[pos]+=eps\n",
    "    return (f(xk + h) - f(xk))/eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el gradiente es las n derivadas parciales ordenadas de xk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente(f,xk):\n",
    "    n = xk.size\n",
    "    res = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        res[i] = derivadaParcial(f,xk,i)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pos1 es la derivada con la cuál se hace la primera derivada parcial, y pos2 le hace la segunda derivada a la función obtenida por la primera derivada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segunda_derivada(f, xk, pos1, pos2):\n",
    "    eps = 0.0001\n",
    "    n = xk.size\n",
    "    h = np.zeros(n)\n",
    "    h[pos2] += eps\n",
    "    def f_prima(x):\n",
    "        return derivada_parcial(f,x,pos1)\n",
    "    return derivada_parcial(f_prima,xk,pos2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la hessiana es la matriz con la combinación de las derivadas parciales de segundo orden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessiana(f,xk):\n",
    "    n = xk.size\n",
    "    res = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            res[i][j] = segunda_derivada(f,xk,i,j)\n",
    "    return np.matrix(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "las condiciones de optimalidad dictan que el gradiente tiene que ser diferente al vector 0, y que la hessiana debe ser definida\n",
    "positiva, es decir, todos los eigenvalores positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condiciones_optimalidad(f,xk):\n",
    "    if(np.any(gradiente(f,xk))):\n",
    "        return np.all(np.linalg.eigvals(hessiana(f,xk) > 0))\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mk es para la región de confianza. p es una matriz que representa a un vector columna (nx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk(f, xk, p):\n",
    "    pt= p.transpose()\n",
    "    return f(xk) + pt.dot(gradiente(f,xk)) + .5*(pt.dot((hessiana(f,xk)).dot(p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebo ahora con un ejemplo de f, tomado del libro para ver si los resultados son los esperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 10*(x[1]-x[0]**2)**2 + (1-x[0])**2\n",
    "xk = np.array([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.0019, 20.001 ])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradiente(f,xk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con el libro el gradiente es [-2 20], por lo tanto, el resultado es satisfactorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-3.79999982e+01, -1.99964489e-03],\n",
       "        [-1.99964489e-03,  1.99999999e+01]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessiana(f,xk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con el libro la hessiana es [-38 0; 0 20], por lo tanto el resultado se acerca bastante al correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condiciones_optimalidad(f,xk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[17.7490503]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.matrix([.5,.5]).transpose()\n",
    "mk(f,xk,p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
